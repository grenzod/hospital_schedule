{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d9449bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Union\n",
    "from typing_extensions import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "notebook_dir = Path().absolute()\n",
    "PROJECT_ROOT = notebook_dir.parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "from RAG_SQL.testSQL import get_review_response\n",
    "from RAG_PDF.testPDF import get_response\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ee4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"llama3-70b-8192\", model_provider=\"groq\")\n",
    "router_llm = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d4cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouterOutput(BaseModel):\n",
    "    step: Literal[\"sql\", \"pdf\", \"general\"] = Field(\n",
    "        description=\"The next step in the routing process\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        description=\"Confidence score between 0.0 and 1.0 for the chosen route\",\n",
    "        ge=0.0,\n",
    "        le=1.0\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Detailed reasoning for why this route was chosen\"\n",
    "    )\n",
    "    \n",
    "router = router_llm.with_structured_output(RouterOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136f4bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    input: str\n",
    "    conversation_history: List[Dict[str, str]]\n",
    "    messages: List\n",
    "    decision: Dict[str, Union[str, float, str]]\n",
    "    output: StrOutputParser\n",
    "    context: Optional[str]\n",
    "    source: Optional[str]\n",
    "    fallback_attempts: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f158fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_rag_node(state: State) -> Dict:\n",
    "    try:\n",
    "        result = get_review_response(state[\"messages\"])\n",
    "        if not result or len(result.strip()) < 10:\n",
    "            return {\n",
    "                \"output\": \"I couldn't find relevant database information. Would you like me to search our medical documents instead?\",\n",
    "                \"source\": \"sql\",\n",
    "                \"fallback_attempts\": state.get(\"fallback_attempts\", 0) + 1\n",
    "            }\n",
    "        return {\n",
    "            \"output\": result,\n",
    "            \"source\": \"sql\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"output\": f\"I encountered an issue while searching the database. Let me try a different approach.\",\n",
    "            \"fallback_attempts\": state.get(\"fallback_attempts\", 0) + 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7b1c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_rag_node(state: State) -> Dict:\n",
    "    try:\n",
    "        result = get_response(state[\"messages\"])\n",
    "        if not result or len(result.strip()) < 10:\n",
    "            return {\n",
    "                \"output\": \"I couldn't find relevant information in our medical documents. Let me provide a general response.\",\n",
    "                \"source\": \"pdf\",\n",
    "                \"fallback_attempts\": state.get(\"fallback_attempts\", 0) + 1\n",
    "            }\n",
    "        return {\n",
    "            \"output\": result,\n",
    "            \"source\": \"pdf\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"output\": f\"I encountered an issue while searching our medical documents. Let me try a different approach.\",\n",
    "            \"fallback_attempts\": state.get(\"fallback_attempts\", 0) + 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03910c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_qa_node(state: State) -> Dict:\n",
    "    try:\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a helpful AI assistant that maintains conversation context and answers questions accurately and answer me using Vietnamese.\"),\n",
    "            *state[\"messages\"]  \n",
    "        ]\n",
    "        \n",
    "        result = llm.invoke(messages)\n",
    "        \n",
    "        return {\n",
    "            \"output\": result.content,\n",
    "            \"source\": \"general\",\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in general_qa_node: {str(e)}\")\n",
    "        return {\n",
    "            \"output\": \"I encountered an error processing your request. Could you please rephrase your question?\",\n",
    "            \"source\": \"general\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c25d6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_node(state: State) -> Dict:    \n",
    "    # Initialize fallback attempts if not present\n",
    "    if \"fallback_attempts\" not in state:\n",
    "        state[\"fallback_attempts\"] = 0\n",
    "    \n",
    "    conversation_context = \"\"\n",
    "    if state[\"conversation_history\"]:\n",
    "        conversation_context = \"\\nRecent conversation history:\\n\"\n",
    "        for entry in state[\"conversation_history\"][-3:]:\n",
    "            conversation_context += f\"{entry['role'].capitalize()}: {entry['content']}\\n\"\n",
    "\n",
    "    decision = router.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=f\"\"\"You are a specialized medical query router. Your task is to analyze the input query and determine the MOST APPROPRIATE processing step. Choose one of:\n",
    "\n",
    "                - 'sql': For queries about:\n",
    "                  * Database information, structured data questions\n",
    "                  * Doctor reviews, ratings, or performance metrics\n",
    "                  * Patient feedback or experiences with specific doctors\n",
    "                  * Any queries requiring retrieval from structured databases\n",
    "                  * Examples: \"What's Dr. Smith's rating?\", \"Show patient feedback for Dr. Johnson\"\n",
    "\n",
    "                - 'pdf': For queries about:\n",
    "                  * Disease symptoms, treatments, or medical conditions\n",
    "                  * Healthcare procedures or medical advice\n",
    "                  * Medical guidelines or protocols\n",
    "                  * Any queries requiring retrieval from medical documents\n",
    "                  * Examples: \"What are the symptoms of dengue?\", \"How is malaria treated?\"\n",
    "\n",
    "                - 'general': For queries that are:\n",
    "                  * Non-medical, casual, or general conversation\n",
    "                  * Not requiring specific medical data\n",
    "                  * Follow-up questions about previous responses\n",
    "                  * Examples: \"Thank you\", \"Can you explain that more simply?\"\n",
    "\n",
    "                Focus on the core content of the query and ignore greetings or polite phrases. \n",
    "                Select the most appropriate step based on the query's intent and content.\n",
    "                Provide a confidence score between 0 and 1.\n",
    "                {state['conversation_history']}\n",
    "                \"\"\"\n",
    "            ),\n",
    "            HumanMessage(content=state[\"input\"]),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return {\"decision\": {\n",
    "        \"step\": decision.step,\n",
    "        \"confidence\": decision.confidence,\n",
    "        \"reasoning\": decision.reasoning\n",
    "    }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cec7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fallback_router(state: State) -> str:\n",
    "    if state.get(\"fallback_attempts\", 0) >= 2:\n",
    "        return \"General\"  # After 2 failed attempts, go to general QA\n",
    "    \n",
    "    # Check if we've already tried the current source\n",
    "    if state.get(\"source\") == \"sql\":\n",
    "        return \"Pdf\"\n",
    "    elif state.get(\"source\") == \"pdf\":\n",
    "        return \"General\"\n",
    "    \n",
    "    # Default routing\n",
    "    decision = state[\"decision\"][\"step\"]\n",
    "    confidence = state[\"decision\"][\"confidence\"]\n",
    "    \n",
    "    # Low confidence routing\n",
    "    if confidence < 0.7:\n",
    "        if decision == \"sql\":\n",
    "            if \"database\" in state[\"input\"].lower() or \"doctor\" in state[\"input\"].lower():\n",
    "                return \"Sql\"\n",
    "            else:\n",
    "                return \"Pdf\"\n",
    "        elif decision == \"pdf\":\n",
    "            if \"disease\" in state[\"input\"].lower() or \"symptom\" in state[\"input\"].lower():\n",
    "                return \"Pdf\"\n",
    "            else:\n",
    "                return \"General\"\n",
    "    \n",
    "    # High confidence routing\n",
    "    if decision == \"sql\":\n",
    "        return \"Sql\"\n",
    "    elif decision == \"pdf\":\n",
    "        return \"Pdf\"\n",
    "    else:\n",
    "        return \"General\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff42cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_builder = StateGraph(State)\n",
    "\n",
    "router_builder.add_node(\"Router\", router_node)\n",
    "router_builder.add_node(\"Sql\", sql_rag_node)\n",
    "router_builder.add_node(\"Pdf\", pdf_rag_node)\n",
    "router_builder.add_node(\"General\", general_qa_node)\n",
    "\n",
    "router_builder.add_edge(START, \"Router\")\n",
    "router_builder.add_conditional_edges(\n",
    "    \"Router\",\n",
    "    fallback_router,\n",
    "    {\n",
    "        \"Sql\": \"Sql\",\n",
    "        \"Pdf\": \"Pdf\",\n",
    "        \"General\": \"General\",\n",
    "    },\n",
    ")\n",
    "\n",
    "router_builder.add_conditional_edges(\n",
    "    \"Sql\",\n",
    "    lambda state: \"Router\" if state.get(\"fallback_attempts\", 0) > 0 else END,\n",
    "    {\n",
    "        \"Router\": \"Router\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "router_builder.add_conditional_edges(\n",
    "    \"Pdf\",\n",
    "    lambda state: \"Router\" if state.get(\"fallback_attempts\", 0) > 0 else END,\n",
    "    {\n",
    "        \"Router\": \"Router\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "router_builder.add_edge(\"General\", END)\n",
    "router_workflow = router_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(router_workflow.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9bb80a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\TIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Decision: pdf (Confidence: 0.8)\n",
      "Reasoning: The query appears to be related to a specific medical condition or symptom, making 'pdf' the most appropriate step.\n",
      "Output: I don't know the answer to this question as the provided context does not mention what to do if you have symptoms of a headache. The context appears to be related to dengue fever and its surveillance in Timor-Leste.\n"
     ]
    }
   ],
   "source": [
    "history = [\n",
    "    # {\"role\": \"user\", \"content\": \"tôi cho số bí mật là 175003 bạn nhớ chưa?\"},\n",
    "    # {\"role\": \"assistant\", \"content\": \"I remember! Your secret number is 175003.\", \"source\": \"general\"},\n",
    "    # {\"role\": \"user\", \"content\": \"Số bí mật tôi vừa nói là gì và tính xem 1 + 1 = mấy ?\"},\n",
    "    # {\"role\": \"assistant\", \"content\": \"I remember! Your secret number is 175003. And, of course, 1 + 1 = 2\"},\n",
    "    # {\"role\": \"user\",      \"content\": \"Những bệnh nhân nói gì về bác sĩ John Doe trong bệnh viện này\"},\n",
    "    # {\"role\": \"assistant\", \"content\": \"Từ các đánh giá và phản hồi của bệnh nhân, bác sĩ John Doe tại bệnh viện này được đánh giá cao về tính chuyên nghiệp,\" + \n",
    "    # \"thái độ thân thiện và kỹ năng chẩn đoán bệnh chính xác. Một số bệnh nhân đã chia sẻ rằng bác sĩ John Doe đã dành thời gian để lắng nghe và trả lời các câu\" + \n",
    "    # \"hỏi của họ, khiến họ cảm thấy an toàn và tin tưởng. Ngoài ra, bác sĩ Doe cũng được biết đến với khả năng giải thích các vấn đề sức khỏe một cách rõ ràng và\" + \n",
    "    # \"dễ hiểu, giúp bệnh nhân có thể hiểu và tuân thủ các hướng dẫn điều trị. Tuy nhiên, một số bệnh nhân cũng đã nêu ra một số vấn đề nhỏ, chẳng hạn như thời gian\" + \n",
    "    # \"chờ đợi lâu hoặc khó có thể liên hệ với bác sĩ Doe sau giờ làm việc. Tuy nhiên, nhìn chung, đa số bệnh nhân đều rất hài lòng với dịch vụ y tế của bác sĩ John Doe\" + \n",
    "    # \"tại bệnh viện này\"},\n",
    "    {\"role\": \"user\", \"content\": \"Thế nếu tôi gắp triệu chứng đau đầu thì nên làm sao\"},\n",
    "]\n",
    "messages = []\n",
    "for entry in history:\n",
    "    if entry[\"role\"] == \"user\":\n",
    "        messages.append(HumanMessage(content=entry[\"content\"]))\n",
    "    else:\n",
    "        messages.append(AIMessage(content=entry[\"content\"]))\n",
    "\n",
    "state = router_workflow.invoke({\n",
    "    \"input\": history[-1][\"content\"],\n",
    "    \"conversation_history\": history,\n",
    "    \"messages\": messages\n",
    "})\n",
    "print(f\"Decision: {state['decision']['step']} (Confidence: {state['decision']['confidence']})\")\n",
    "print(f\"Reasoning: {state['decision']['reasoning']}\")\n",
    "print(f\"Output: {state['output']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
